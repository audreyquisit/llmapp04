services:
  llm-python:
    build: ./llm-python
    container_name: llm-python
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-gemma3:4b}
      - OLLAMA_API_KEY=${OLLAMA_API_KEY:-c2f916de66c04c729cf98a25c93abe56._U5Dy3DoDf1RQ9BG936-yC4R}
    networks:
      - llm-network

  llm-frontend-python:
    build: ./llm-frontend-python
    container_name: llm-frontend-python
    ports:
      - "5000:5000"
    environment:
      - BACKEND_URL=http://llm-python:8080
    depends_on:
      - llm-python
    networks:
      - llm-network

networks:
  llm-network:
    driver: bridge

